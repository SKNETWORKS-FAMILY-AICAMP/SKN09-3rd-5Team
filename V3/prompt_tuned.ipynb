{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQxiezl0HwJt",
        "outputId": "6e94cb06-3067-4f04-e081-db287487b698"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.50.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (0.29.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2025.1.31)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement re (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for re\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for os\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: typing in /usr/local/lib/python3.11/dist-packages (3.7.4.3)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.21)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.47)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.18)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.50.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.5.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.29.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2025.1.31)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement faiss (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for faiss\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting sklearn\n",
            "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Collecting dotenv\n",
            "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
            "Collecting python-dotenv (from dotenv)\n",
            "  Using cached python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv, dotenv\n",
            "Successfully installed dotenv-0.9.9 python-dotenv-1.1.0\n",
            "Collecting langchain-community\n",
            "  Using cached langchain_community-0.3.20-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.47)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.21 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.21)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Using cached pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.18)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.21->langchain-community) (0.3.7)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.21->langchain-community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain-community) (2.27.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Using cached langchain_community-0.3.20-py3-none-any.whl (2.5 MB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.20 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 typing-inspect-0.9.0\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (4.12.2)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11679 sha256=ee5effc1ae7f7378dfea6e493d9b4980c6960d1d9f294d7fde0f70bc1b7df787\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install sentence_transformers\n",
        "!pip install torch\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install re\n",
        "!pip install os\n",
        "!pip install typing\n",
        "!pip install langchain\n",
        "!pip install peft\n",
        "!pip install faiss\n",
        "!pip install sklearn\n",
        "!pip install dotenv\n",
        "!pip install langchain-community\n",
        "!pip install faiss-cpu\n",
        "!pip install wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U peft langchain-huggingface"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5keDpauPIadT",
        "outputId": "ebc6a7c0-6c7a-42fa-aecc-c9cca2eca434"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Collecting peft\n",
            "  Downloading peft-0.15.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain-huggingface\n",
            "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.50.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.5.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.29.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.3.47)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (3.4.1)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.21.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (4.12.2)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.3.18)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.10.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.14.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.14.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.3.1)\n",
            "Downloading peft-0.15.1-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.0/411.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: peft, langchain-huggingface\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.14.0\n",
            "    Uninstalling peft-0.14.0:\n",
            "      Successfully uninstalled peft-0.14.0\n",
            "Successfully installed langchain-huggingface-0.1.2 peft-0.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPDRrs_iSj8t",
        "outputId": "b032182b-20f2-4335-bbeb-bee0af685cdd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/981.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m972.8/981.5 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=a41c5b23ee00df70bdd379f581abcddfa109e7c8f745f69dbf80d6bd25f22f54\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, DebertaV2TokenizerFast\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "from typing import List, Optional, Dict, Any\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import ConversationalRetrievalChain, LLMChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import BaseLLM, HuggingFaceHub\n",
        "from langchain.agents import Tool, AgentExecutor, ZeroShotAgent\n",
        "from langchain.utilities import WikipediaAPIWrapper\n",
        "from langchain.tools import WikipediaQueryRun\n",
        "from langchain_core.outputs import Generation\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from peft import PeftModel, PeftConfig, PeftModelForQuestionAnswering\n",
        "import faiss\n",
        "from sklearn.preprocessing import normalize\n",
        "from google.colab import userdata\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "# 병렬 토크나이저 경고 방지\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "# LoRA 설정 로드\n",
        "peft_config = PeftConfig.from_pretrained(\"./drive/MyDrive/3rd_project/trained_V3_LoRA\")\n",
        "\n",
        "# 기본 모델 로드\n",
        "loaded_model = AutoModelForQuestionAnswering.from_pretrained(peft_config.base_model_name_or_path)\n",
        "\n",
        "# LoRA 어댑터 로드\n",
        "loaded_model = PeftModel.from_pretrained(loaded_model, \"./drive/MyDrive/3rd_project/trained_V3_LoRA\")\n",
        "\n",
        "# 학습된 LoRA 모델 및 토크나이저 로드\n",
        "loaded_model = loaded_model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "loaded_tokenizer = AutoTokenizer.from_pretrained(\"./drive/MyDrive/3rd_project/trained_V3_LoRA\")\n",
        "\n",
        "# 문장 임베딩 모델 로드 (LangChain 호환)\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large\")  # snunlp/KR-SBERT-V40K-klueNLI-augSTS\n",
        "\n",
        "# ✅ 1️⃣ 데이터 로드 (박물관 데이터)\n",
        "data_path = \"./drive/MyDrive/3rd_project/data/merged_museum_data_rag.csv\"\n",
        "df = pd.read_csv(data_path)\n",
        "df = df[['Title', 'Description']].dropna().rename(columns={'Title': 'query', 'Description': 'answer'})\n",
        "\n",
        "# ✅ 문장 분할 함수 (간단한 마침표, 물음표, 느낌표 기준 + 공백 제거)\n",
        "def split_sentences(text):\n",
        "    sentences = re.split(r'(?<=[.?!])\\s+', text.strip())\n",
        "    return [s for s in sentences if s]\n",
        "\n",
        "documents = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    title = row[\"query\"]                    # Title 컬럼\n",
        "    description = row[\"answer\"]             # Description 컬럼\n",
        "    sentences = split_sentences(description)\n",
        "\n",
        "    for sentence in sentences:\n",
        "        documents.append({\n",
        "            \"text\": f\"{title} - {sentence}\",\n",
        "            \"metadata\": {\"title\": title}\n",
        "        })\n",
        "\n",
        "# ✅ 2️⃣ FAISS 벡터스토어 생성 (LangChain)\n",
        "vectorstore = FAISS.from_texts(\n",
        "    texts=[doc[\"text\"] for doc in documents],\n",
        "    embedding=embedding_model,\n",
        "    metadatas=[doc[\"metadata\"] for doc in documents]\n",
        ")\n",
        "\n",
        "# ✅ 'text' 키에 있는 텍스트들을 corpus에 저장\n",
        "corpus = [doc['text'] for doc in documents]\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "# ✅ 3️⃣ Wikipedia 검색 도구 설정\n",
        "wiki_api = WikipediaAPIWrapper(lang=\"ko\")\n",
        "wikipedia_tool = WikipediaQueryRun(api_wrapper=wiki_api)\n",
        "\n",
        "# ✅ 4️⃣ 박물관 데이터 검색 도구 정의\n",
        "def search_museum_data(input):\n",
        "    docs = retriever.get_relevant_documents(input)\n",
        "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "\n",
        "museum_tool = Tool(\n",
        "    name=\"Museum Data Search\",\n",
        "    func=search_museum_data,\n",
        "    description=\"useful for when you need to answer questions about artifacts in the National Museum of Korea. Input should be the question.\"\n",
        ")\n",
        "\n",
        "# ✅ 5️⃣ 도구 목록 정의 (Agent가 사용할 도구)\n",
        "tools = [\n",
        "    museum_tool,\n",
        "    Tool(\n",
        "        name=\"Wikipedia Search\",\n",
        "        func=wikipedia_tool.run,\n",
        "        description=\"useful for when you need to answer general questions about the world.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# ✅ 6️⃣ 메모리 설정\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# ✅ 7️⃣ Agent에 사용할 LLM 정의 (일반적인 LLM 필요)\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id=\"ModelSpace/GemmaX2-28-2B-v0.1\",          # GemmaX2-28-2B-v0.1 소환\n",
        "    model_kwargs={\"temperature\": 0.7, \"max_length\": 1024},\n",
        "    # huggingfacehub_api_token=os.environ.get(\"HF_TOKEN\")\n",
        "    huggingfacehub_api_token=userdata.get('HF_TOKEN')\n",
        ")\n",
        "\n",
        "# Agent에 사용할 표준 LLM 코드 (gpt-4o-mini 사용)\n",
        "# openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "# if openai_api_key:\n",
        "#     llm = OpenAI(api_key=openai_api_key, model_name=\"gpt-4o-mini\")\n",
        "# else:\n",
        "#     print(\"OpenAI API 키가 설정되지 않았습니다.\")\n",
        "#     llm = None # 또는 다른 기본 LLM 설정\n",
        "\n",
        "# ✅ 8️⃣ Agent 프롬프트 템플릿\n",
        "prefix = \"\"\"Answer the following questions as best you can. You have access to the following tools:\"\"\"\n",
        "suffix = \"\"\"Previous conversation: {chat_history}\n",
        "\n",
        "Begin!\n",
        "\n",
        "Question: {input}\n",
        "\n",
        "{agent_scratchpad}\"\"\"\n",
        "\n",
        "prompt = ZeroShotAgent.create_prompt(\n",
        "    tools,\n",
        "    prefix=prefix,\n",
        "    suffix=suffix,\n",
        "    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"]\n",
        ")\n",
        "\n",
        "# ✅ 9️⃣ LLMChain 생성\n",
        "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# ✅ 1️⃣0️⃣ Agent 생성\n",
        "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)       # verbose=True로 설정하면 Agent의 사고 과정을 볼 수 있습니다.\n",
        "\n",
        "# ✅ 1️⃣1️⃣ AgentExecutor 생성\n",
        "agent_executor = AgentExecutor.from_agent_and_tools(\n",
        "    agent=agent, tools=tools, verbose=True, memory=memory\n",
        ")\n",
        "\n",
        "# ✅ 1️⃣2️⃣ 사용자 정의 LLM 래퍼 (파인튜닝된 모델 통합) - ConversationalRetrievalChain에 사용\n",
        "class CustomQAmodel(BaseLLM):\n",
        "    model: PeftModelForQuestionAnswering        # 타입 힌트 객체 지정\n",
        "    tokenizer: DebertaV2TokenizerFast           # 타입 힌트 객체 지정\n",
        "    device: str\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"custom_qa_model\"\n",
        "\n",
        "    def _generate(self, prompts: List[str], stop: Optional[List[str]] = None) -> List[Generation]:\n",
        "        full_prompt = prompts[0]\n",
        "        try:\n",
        "            context_match = re.search(r\"Context:\\n(.*?)\\nUser question:\", full_prompt, re.DOTALL)\n",
        "            question_match = re.search(r\"User question:\\n(.*?)(?:\\nPrevious conversation:(.*?))?\\nAnswer:|Question:\\n(.*?)(?:\\nPrevious conversation:(.*?))?\\nAnswer:\", full_prompt, re.DOTALL) # Question 키워드 추가\n",
        "\n",
        "            if not context_match or not question_match:\n",
        "                return [Generation(text=\"Error parsing context or question from prompt.\")]\n",
        "\n",
        "            context_part = context_match.group(1).strip()\n",
        "            question_part = question_match.group(1).strip() if question_match.group(1) else question_match.group(3).strip()    # Question 파싱\n",
        "\n",
        "            chat_history_part = question_match.group(2).strip() if question_match.group(2) else (question_match.group(4).strip() if question_match.group(4) else \"\")        # chat_history 추출하고, chat_history가 없을 경우 빈 문자열 처리\n",
        "\n",
        "        except Exception as e:\n",
        "            return [Generation(text=f\"Error parsing prompt: {e}\")]\n",
        "\n",
        "        # 추출한 chat_history를 모델 입력에 포함하는 방식 결정\n",
        "        # 예시: context와 question 앞에 chat_history를 추가하여 입력\n",
        "        augmented_input = f\"{chat_history_part}\\n{context_part}\\n{question_part}\"\n",
        "\n",
        "        inputs = self.tokenizer(\n",
        "            augmented_input,\n",
        "            truncation=\"only_second\",\n",
        "            max_length=1024,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(self.device)\n",
        "\n",
        "        print(f\"Inputs: {inputs}\")                  # 모델 입력 형태를 확인하기 위해 추가\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "\n",
        "        print(f\"Outputs: {outputs}\")                # 모델 출력 형태를 확인하기 위해 추가\n",
        "\n",
        "        answer_start_scores = outputs.start_logits\n",
        "        answer_end_scores = outputs.end_logits\n",
        "        answer_start = torch.argmax(answer_start_scores)\n",
        "        answer_end = torch.argmax(answer_end_scores) + 1\n",
        "        answer = self.tokenizer.convert_tokens_to_string(self.tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end]))\n",
        "\n",
        "        return [Generation(text=answer.replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip())]\n",
        "\n",
        "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
        "        return self._generate([prompt], stop=stop)[0].text\n",
        "\n"
      ],
      "metadata": {
        "id": "D0vHLjnlIfcc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt_ko = \"\"\"너는 국립중앙박물관에서 일하는 지적이고 친절한 AI 도슨트야.\n",
        "관람객이 어떤 언어로 질문하든 자동으로 언어를 감지하고, 그 언어로 자연스럽고 정확하게 답변해.\n",
        "너는 AI라는 말을 하지 않고, 박물관의 실제 도슨트처럼 행동해야 해.\n",
        "\n",
        "답변 원칙:\n",
        "- 한국어로 답해\n",
        "- 중복된 표현 없이 핵심 정보는 단 한 번만 전달해.\n",
        "- 어색하거나 기계적인 말투는 피하고, 사람처럼 자연스럽고 따뜻한 말투를 사용해.\n",
        "- 질문의 의도를 먼저 파악하려 노력해. 짧거나 모호한 질문이라도 사용자가 무엇을 궁금해하는지 유추해봐.\n",
        "- 유물 설명 시, 관련된 역사적 배경, 제작 방식, 문화적 의미, 출토지 등을 간결히 설명해.\n",
        "- 질문이 불명확하면 먼저 명확히 해달라고 요청해.\n",
        "- 정보를 모를 경우, \"잘 알려지지 않았습니다\" 또는 \"확실하지 않습니다\" 등으로 정직하게 답변해.\n",
        "- 필요 시 관련 유물이나 시대 정보를 추가로 제안해.\n",
        "- 반복되거나 의미 없는 말은 절대 하지 마.\n",
        "- 답변은 RAG 기반으로 구성하며, 신뢰 가능한 출처나 링크가 있다면 함께 제공해.\n",
        "\n",
        "답변 형식:\n",
        "1. 간결하고 핵심적인 답변을 가장 먼저 제시\n",
        "2. 이어서 배경 정보 또는 관련 유물 설명\n",
        "3. 출처 제공(가능한 경우), 중복 문장 금지\n",
        "\n",
        "예시:\n",
        "[질문] 이 유물은 어떤 시대에 만들어졌나요?\n",
        "[답변] 이 유물은 고려 시대(918~1392년)에 제작된 청자로, 왕실에서 의례용으로 사용되었습니다. 강진 지역에서 출토되었으며, 특유의 푸른빛과 정교한 문양이 특징입니다.\n",
        "\"\"\"\n",
        "system_prompt_en = \"\"\"You are a knowledgeable and friendly AI docent at the National Museum of Korea.\n",
        "You must detect the visitor's language automatically and respond fluently and accurately in that language.\n",
        "You must not mention that you are an AI and instead behave like a real museum guide.\n",
        "\n",
        "Answer Guidelines:\n",
        "- Please answer in English.\n",
        "- Deliver key information clearly and only once, avoiding repetition.\n",
        "- Speak in a warm, human-like, and natural tone—never robotic or awkward.\n",
        "- Try to understand the intent behind each question, even if it is short or vague.\n",
        "- When explaining artifacts, include historical background, production methods, cultural context, and excavation sites concisely.\n",
        "- If the question is unclear, ask the user to clarify before answering.\n",
        "- If the information is unknown, respond honestly: e.g., \"This is not well known\" or \"The details are unclear.\"\n",
        "- Suggest related artifacts or historical periods when appropriate.\n",
        "- Never repeat unnecessary phrases or filler words.\n",
        "- Build your answers based on RAG (Retrieval-Augmented Generation). If possible, provide credible sources or links.\n",
        "\n",
        "Answer Format:\n",
        "1. Present the concise and essential answer first\n",
        "2. Follow with contextual or background explanations\n",
        "3. Include sources if available, and avoid redundant sentences\n",
        "\n",
        "Examples:\n",
        "[Question] When was this artifact made?\n",
        "[Answer] This artifact is a celadon piece from the Goryeo Dynasty (918–1392), traditionally used in royal rituals. It was excavated from the Gangjin region and is known for its distinctive bluish-green glaze and intricate patterns.\"\"\"  # 생략\n",
        "system_prompt_ja = \"\"\"あなたは国立中央博物館で働く、知的で親切なAIドーセントです。来館者がどの言語で質問しても、自動的に言語を判別し、その言語で自然かつ正確に答えてください。\n",
        "自分がAIであることは言わず、本物の博物館ガイドのように振る舞ってください。\n",
        "\n",
        "回答のルール：\n",
        "- 日本語で答えてください。\n",
        "- 情報は簡潔に、一度だけ伝え、繰り返さないでください。\n",
        "- 不自然な表現や機械的な言い回しは避け、温かく、親しみやすい口調を使ってください。\n",
        "- 質問の意図をまず理解しようとしてください。短い質問や曖昧な表現でも、来館者の意図を推測してみてください。\n",
        "- 遺物を説明する際は、その歴史的背景、製作方法、文化的な意味、出土場所などを簡潔に紹介してください。\n",
        "- 質問が不明確な場合は、まず内容を明確にしてもらうようお願いしてください。\n",
        "- 情報が不明な場合は、「よくわかっていません」や「詳細は不明です」など、正直に答えてください。\n",
        "- 必要に応じて関連する遺物や時代の情報を提案してください。\n",
        "- 無意味な繰り返しや決まり文句は絶対に避けてください。\n",
        "- 回答はRAG（検索拡張生成）に基づいて行い、信頼できる情報源やリンクがあれば一緒に提示してください。\n",
        "\n",
        "回答形式：\n",
        "1. まず、簡潔で重要な情報を先に述べる\n",
        "2. 次に、背景や関連情報を説明する\n",
        "3. 可能であれば情報源を提示し、重複表現は避ける\n",
        "\n",
        "例：\n",
        "［質問］この遺物はいつの時代に作られたものですか？\n",
        "［回答］この遺物は高麗時代（918～1392年）に制作された青磁で、王室の儀式に使われていたとされています。全羅南道の康津（カンジン）地域で出土しており、独特な青緑色の釉薬と精緻な文様が特徴です。\n",
        "\"\"\"\n",
        "\n",
        "# 🌐 언어 자동 감지 함수\n",
        "from langdetect import detect\n",
        "\n",
        "def detect_language(text):\n",
        "    try:\n",
        "        return detect(text)\n",
        "    except:\n",
        "        return \"ko\"  # default\n",
        "\n",
        "# 🌟 사용자 질문 기반으로 프롬프트 템플릿 생성\n",
        "def get_prompt_template(user_input):\n",
        "    lang = detect_language(user_input)\n",
        "    if lang == \"ja\":\n",
        "        prompt = system_prompt_japan\n",
        "    elif lang == \"en\":\n",
        "        prompt = system_prompt_eng\n",
        "    else:\n",
        "        prompt = system_prompt\n",
        "\n",
        "    return PromptTemplate(\n",
        "        template=f\"\"\"{prompt}\n",
        "\n",
        "Context: {{context}}\n",
        "\n",
        "User question: {{query}}\n",
        "\n",
        "Previous conversation: {{chat_history}}\n",
        "\n",
        "Answer:\"\"\",\n",
        "        input_variables=[\"context\", \"query\", \"chat_history\"]\n",
        "    )\n",
        "\n",
        "qa = ConversationalRetrievalChain.from_llm(\n",
        "    llm=CustomQAmodel(model=loaded_model, tokenizer=loaded_tokenizer, device=device),\n",
        "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
        "    memory=memory,\n",
        "    chain_type=\"stuff\",\n",
        "    combine_docs_chain_kwargs={\"prompt\": get_prompt_template(user_question)}  # <- 여기 핵심!\n",
        ")  # ConversationalRetrievalChain\n",
        "\n",
        "# ✅ 1️⃣5️⃣ 코사인 유사도\n",
        "def retrieve_context_semantic_cosine(query, top_k=3, similarity_threshold=-0.5):         # 임계값 조정 (cosine similarity inner product 기반에서 변경)\n",
        "    query_embedding = embedding_model.embed_query(query)\n",
        "    # 리스트를 NumPy 배열로 변환 후 쿼리 임베딩 정규화\n",
        "    query_embedding_array = np.array(query_embedding)\n",
        "    query_embedding_normalized = normalize(query_embedding_array.reshape(1, -1), axis=1)\n",
        "    distances, indices = vectorstore.index.search(np.array(query_embedding_normalized), top_k)\n",
        "    filtered_context = []\n",
        "    for i in range(len(distances[0])):\n",
        "        # 코사인 유사도는 높을수록 유사하므로, 임계값보다 큰 경우만 포함\n",
        "        if distances[0][i] > similarity_threshold:\n",
        "            filtered_context.append(corpus[indices[0][i]])\n",
        "    return \" \".join(filtered_context)\n",
        "\n",
        "# ✅ 1️⃣6️⃣ 답변 생성 함수\n",
        "def generate_answer(question, context):\n",
        "    \"\"\"검색된 문맥을 활용하여 답변을 생성하는 함수 (현재는 간단히 문맥을 반환)\"\"\"\n",
        "    if context:\n",
        "        return f\"질문하신 {question}에 대해 찾아본 결과는 다음과 같습니다:\\n\\n{context}\\n\"\n",
        "    else:\n",
        "        return \"죄송하지만, 관련된 정보를 찾지 못했습니다.\"\n",
        "\n",
        "while True:\n",
        "    user_question = input(\"궁금한 점을 질문해주세요 (종료하려면 'exit' 입력): \")\n",
        "    if user_question.lower() == 'exit':\n",
        "        print(\"도슨트 서비스를 종료합니다.\")\n",
        "        break\n",
        "\n",
        "    context = retrieve_context_semantic_cosine(user_question)\n",
        "    answer = generate_answer(user_question, context)\n",
        "\n",
        "    # 박물관 데이터에서 맥락을 찾지 못한 경우 (답변이 부실하거나 특정 키워드를 포함하는 경우), Agent 실행\n",
        "    if \"죄송합니다. 제가 가진 정보로는 질문에 대한 구체적인 답변을 드릴 수 없습니다.\" in answer or \"unknown\" in answer.lower() or \"not sure\" in answer.lower():\n",
        "        print(\"박물관 데이터에서는 관련 정보를 찾지 못했습니다. 위키피디아에서 검색을 시도합니다....\")\n",
        "        result_agent = agent_executor.run({\"input\": user_question})          # Agent 실행 시 chat_history는 메모리에서 관리\n",
        "        print(f\"질문 (위키피디아): {user_question}\")\n",
        "        print(f\"답변 (위키피디아): {result_agent}\")\n",
        "    else:\n",
        "        print(f\"질문 (박물관 데이터): {user_question}\")\n",
        "        print(f\"답변 (박물관 데이터): {answer}\")\n",
        "\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "k4UUvuk0N7e6",
        "outputId": "1e66ebfc-d843-4928-be85-69a32ebb5dcf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "궁금한 점을 질문해주세요 (종료하려면 'exit' 입력): 겨울 산수에 대해서 알려줘\n",
            "질문 (박물관 데이터): 겨울 산수에 대해서 알려줘\n",
            "답변 (박물관 데이터): 질문하신 겨울 산수에 대해서 알려줘에 대해 찾아본 결과는 다음과 같습니다:\n",
            "\n",
            "겨울 산수 (冬景山水圖) - 이 작품에서는 간략한 필치와 단순한 형태 엷지만 선명한 색채가 두드러진다. 겨울 산수 (冬景山水圖) - 산과 바위를 연한 먹빛으로 칠하고 태점(苔點 : 산이나 바위 땅 또는 나무 줄기에 난 이끼를 표현하는 작은 점)을 찍어 장식적 효과를 높이고 있다. 겨울 산수 (冬景山水圖) - 온통 먹빛인 가운데 임포가 머물고 있는 집과 임포의 옷색은 붉은색이며 다리 건너 그를 찾아오는 이의 옷은 푸른색으로 서로 산뜻한 대비를 이룬다.\n",
            "\n",
            "\n",
            "\n",
            "궁금한 점을 질문해주세요 (종료하려면 'exit' 입력): 겨울 산수의 작가는 누구야?\n",
            "질문 (박물관 데이터): 겨울 산수의 작가는 누구야?\n",
            "답변 (박물관 데이터): 질문하신 겨울 산수의 작가는 누구야?에 대해 찾아본 결과는 다음과 같습니다:\n",
            "\n",
            "겨울 산수 (冬景山水圖) - 이 작품에서는 간략한 필치와 단순한 형태 엷지만 선명한 색채가 두드러진다. 가을 산수 (金昌秀筆秋景山水圖 김창수 필 추경산수도) - 감창수(號 鶴山)는 생애와 활동 내역에 대해 현재까지 전해지는 기록이 거의 없는 화가이다. 겨울 산수 (冬景山水圖) - 산과 바위의 음영 표현 없이 윤곽선만으로 표현되어 김수철 그림의 특징인 간결함이 잘 드러나 있다.\n",
            "\n",
            "\n",
            "\n",
            "궁금한 점을 질문해주세요 (종료하려면 'exit' 입력): 작가가 누구야?\n",
            "질문 (박물관 데이터): 작가가 누구야?\n",
            "답변 (박물관 데이터): 질문하신 작가가 누구야?에 대해 찾아본 결과는 다음과 같습니다:\n",
            "\n",
            "자하 신위가 쓴 글씨 (紫霞 申緯 筆 詩句) - 자하(紫霞) 신위(申緯 1769~1847)가 행서(行書)로 쓴? 자하 신위가 쓴 글씨 (紫霞 申緯 筆 詩句) - 신위는 조선 후기의 시서화 삼절(詩書? 우암 송시열이 쓴 「해동의 하늘과 땅」 (尤庵 宋時烈 筆 海東乾坤 尊周大義) - 강한 필획과 흘림 기운이 큰 강건한 필치 및?\n",
            "\n",
            "\n",
            "\n",
            "궁금한 점을 질문해주세요 (종료하려면 'exit' 입력): 아니 내가 첫번째 물어봤던 유물의 작가를 알려줘\n",
            "질문 (박물관 데이터): 아니 내가 첫번째 물어봤던 유물의 작가를 알려줘\n",
            "답변 (박물관 데이터): 질문하신 아니 내가 첫번째 물어봤던 유물의 작가를 알려줘에 대해 찾아본 결과는 다음과 같습니다:\n",
            "\n",
            "채미도 (採薇圖) - 鄂彼晨? 중국도자 천목유완 - 중국도자 천목유완(2-1). 아기 업은 여인 - 신윤복(申潤福 1758?\n",
            "\n",
            "\n",
            "\n",
            "궁금한 점을 질문해주세요 (종료하려면 'exit' 입력): I want to know about winterlandscape\n",
            "질문 (박물관 데이터): I want to know about winterlandscape\n",
            "답변 (박물관 데이터): 질문하신 I want to know about winterlandscape에 대해 찾아본 결과는 다음과 같습니다:\n",
            "\n",
            "물가 풍경 - *물가 풍경. 어촌 풍경 - 어촌 풍경. 농촌 풍경 - 농촌 풍경.\n",
            "\n",
            "\n",
            "\n",
            "궁금한 점을 질문해주세요 (종료하려면 'exit' 입력): 冬の算数について教えてください\n",
            "질문 (박물관 데이터): 冬の算数について教えてください\n",
            "답변 (박물관 데이터): 질문하신 冬の算数について教えてください에 대해 찾아본 결과는 다음과 같습니다:\n",
            "\n",
            "天文圖 (천문도) - 망실분 4점 꽃과 새 (花鳥圖) - 화면 오른쪽 중간에 ‘丁亥冬墨? 乘馬土偶 - 右前脚失.\n",
            "\n",
            "\n",
            "\n",
            "궁금한 점을 질문해주세요 (종료하려면 'exit' 입력): 목제 인형에 대해서 알려줘\n",
            "질문 (박물관 데이터): 목제 인형에 대해서 알려줘\n",
            "답변 (박물관 데이터): 질문하신 목제 인형에 대해서 알려줘에 대해 찾아본 결과는 다음과 같습니다:\n",
            "\n",
            "목제 인형 (人形) - 투루판의 시르캅(斯瑞克普)에서 출토된 것으로 추정된다. 목제 인형 (人形) - 매우 드문 유형의 자료로 이 지역에 거주했던 이들의 머리 모양이나 옷차림 장신구에 관한 중요한 정보를 제공해 준다. 목제 인형 (人形) - 송대(宋代) 제작된 것으로 보이나 두건의 형태로 보아 몽고인을 묘사했을 가능성도 있다.\n",
            "\n",
            "\n",
            "\n",
            "궁금한 점을 질문해주세요 (종료하려면 'exit' 입력): 투루판이 뭐야?\n",
            "질문 (박물관 데이터): 투루판이 뭐야?\n",
            "답변 (박물관 데이터): 질문하신 투루판이 뭐야?에 대해 찾아본 결과는 다음과 같습니다:\n",
            "\n",
            "불두 (粘土製佛頭) - 투루판에서 출토된 것이다. 손잡이 단지 (素燒把手附壺) - 이와 같은 예는 투루판 뿐 아니라 쿠처의 스바시에서도 볼 수 있다. 목편 (木片) - 투루판에서 출토되었다.\n",
            "\n",
            "\n",
            "\n",
            "궁금한 점을 질문해주세요 (종료하려면 'exit' 입력): 투루판이 뭐야?\n",
            "질문 (박물관 데이터): 투루판이 뭐야?\n",
            "답변 (박물관 데이터): 질문하신 투루판이 뭐야?에 대해 찾아본 결과는 다음과 같습니다:\n",
            "\n",
            "불두 (粘土製佛頭) - 투루판에서 출토된 것이다. 손잡이 단지 (素燒把手附壺) - 이와 같은 예는 투루판 뿐 아니라 쿠처의 스바시에서도 볼 수 있다. 목편 (木片) - 투루판에서 출토되었다.\n",
            "\n",
            "\n",
            "\n",
            "궁금한 점을 질문해주세요 (종료하려면 'exit' 입력): exit\n",
            "도슨트 서비스를 종료합니다.\n"
          ]
        }
      ]
    }
  ]
}